{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import sklearn\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgmDataFile = './Project-1-Files/CGMData.csv'\n",
    "insDataFile = './Project-1-Files/InsulinData.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1: Read data along with parsed dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (13,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "cgmData = pd.read_csv(cgmDataFile, parse_dates=[['Date', 'Time']])#, keep_date_col=True)\n",
    "insData = pd.read_csv(insDataFile, parse_dates=[['Date', 'Time']])#, keep_date_col=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus only on datetime and Sensor Glucose data columns\n",
    "cgmData = cgmData[['Date_Time', 'Sensor Glucose (mg/dL)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: create 6 columns specifying each type of hyperglycemia ranges for that row's CGM value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different types of Hyperglycemia ranges\n",
    "HGC_Ranges = ['HGC', 'HGC_C', 'HGC_R1', 'HGC_R2', 'HGC_L1', 'HGC_L2']\n",
    "# TYPE 1: Hyperglycemia (HGC)\n",
    "cgmData[HGC_Ranges[0]] = cgmData['Sensor Glucose (mg/dL)'] > 180\n",
    "# TYPE 2: Hyperglycemia Critical (HGC_C)\n",
    "cgmData[HGC_Ranges[1]] = cgmData['Sensor Glucose (mg/dL)'] > 250\n",
    "# TYPE 3: Hyperglycemia Range 1 (HGC_R1)\n",
    "cgmData[HGC_Ranges[2]] = cgmData['Sensor Glucose (mg/dL)'].between(70, 180, inclusive='both')\n",
    "# TYPE 4: Hyperglycemia Range 2 (HGC_R2)\n",
    "cgmData[HGC_Ranges[3]] = cgmData['Sensor Glucose (mg/dL)'].between(70, 150, inclusive='both')\n",
    "# TYPE 5: Hyperglycemia Level 1 (HGC_L1)\n",
    "cgmData[HGC_Ranges[4]] = cgmData['Sensor Glucose (mg/dL)'] < 70\n",
    "# TYPE 6: Hyperglycemia Level 2 (HGC_L2)\n",
    "cgmData[HGC_Ranges[5]] = cgmData['Sensor Glucose (mg/dL)'] < 54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3: look for 'AUTO MODE ACTIVE PLGM OFF' in insData and get corresponding Date_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_T_A for Date, Time, Alarm\n",
    "insData_D_T_A = insData[['Date_Time', 'Alarm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 'AUTO MODE ACTIVE PLGM OFF' date and timestamp\n",
    "autoOnData = insData_D_T_A[insData_D_T_A['Alarm'] == 'AUTO MODE ACTIVE PLGM OFF']\n",
    "# get the earliest Date_Time value index\n",
    "autoOnIndex = autoOnData['Date_Time'].idxmin()\n",
    "# index the earliest DateTime\n",
    "autoOnDateTime = insData_D_T_A.iloc[autoOnIndex]['Date_Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4: handle missing/NaN data (USING deletion of the entire day if NaN present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data\n",
    "cgmData['Valid_Day'] = cgmData.groupby(pd.Grouper(key='Date_Time', freq='1D'))['Sensor Glucose (mg/dL)'].transform(lambda x: True if (x.count() >= 231 and x.count() <= 288) else False)\n",
    "cgmData_filt = cgmData[cgmData['Valid_Day']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5: get corresponding Manual/Auto data based on the autoOnDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times BEFORE autoOnDateTime are MANUAL MODE\n",
    "cgmData_D_T_R_Man = cgmData_filt[ cgmData_filt['Date_Time'] < autoOnDateTime ].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times AFTER/ON autoOnDateTime are AUTO MODE\n",
    "cgmData_D_T_R_Aut = cgmData_filt[ cgmData_filt['Date_Time'] >= autoOnDateTime ].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to see if data extracted is labelled correctly\n",
    "if (cgmData_D_T_R_Man['Date_Time'].max() <= autoOnDateTime < cgmData_D_T_R_Aut['Date_Time'].min()) is False:\n",
    "    print(\"ERROR: The extracted parts Manual and Auto DO NOT make sense chronologically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 6: extract data for different segments and sub-segments of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL data\n",
    "cgm_OvrNight_Man = cgmData_D_T_R_Man[(cgmData_D_T_R_Man['Date_Time'].dt.hour >= 0) & \n",
    "                  (cgmData_D_T_R_Man['Date_Time'].dt.hour < 6)].copy(deep=True)\n",
    "cgm_DayTime_Man = cgmData_D_T_R_Man[(cgmData_D_T_R_Man['Date_Time'].dt.hour >= 6) & \n",
    "                  (cgmData_D_T_R_Man['Date_Time'].dt.hour <= 23)].copy(deep=True)\n",
    "cgm_WholeDay_Man = cgmData_D_T_R_Man.copy(deep=True)\n",
    "\n",
    "# AUTO data\n",
    "cgm_OvrNight_Aut = cgmData_D_T_R_Aut[(cgmData_D_T_R_Aut['Date_Time'].dt.hour >= 0) & \n",
    "                  (cgmData_D_T_R_Aut['Date_Time'].dt.hour < 6)].copy(deep=True)\n",
    "cgm_DayTime_Aut = cgmData_D_T_R_Aut[(cgmData_D_T_R_Aut['Date_Time'].dt.hour >= 6) & \n",
    "                  (cgmData_D_T_R_Aut['Date_Time'].dt.hour <= 23)].copy(deep=True)\n",
    "cgm_WholeDay_Aut = cgmData_D_T_R_Aut.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Overnight Manual: 936\n",
      "Len Daytime Manual: 2615\n",
      "Len Overnight Auto: 10865\n",
      "Len Daytime Auto: 32730\n",
      "Total: 47146\n"
     ]
    }
   ],
   "source": [
    "print(\"Len Overnight Manual: \" + str(len(cgm_OvrNight_Man)))\n",
    "print(\"Len Daytime Manual: \" + str(len(cgm_DayTime_Man)))\n",
    "print(\"Len Overnight Auto: \" + str(len(cgm_OvrNight_Aut)))\n",
    "print(\"Len Daytime Auto: \" + str(len(cgm_DayTime_Aut)))\n",
    "print(\"Total: \"+str(len(cgm_OvrNight_Man)+len(cgm_DayTime_Man)+len(cgm_OvrNight_Aut)+len(cgm_DayTime_Aut)))\n",
    "# checking if all the rows are extracted\n",
    "if ( (len(cgm_OvrNight_Man)+len(cgm_DayTime_Man) != len(cgm_WholeDay_Man)) or\n",
    "     (len(cgm_OvrNight_Aut)+len(cgm_DayTime_Aut) != len(cgm_WholeDay_Aut)) ):\n",
    "    print(\"ERROR: The length of extracted subsegments of data DP NOT mactch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 7: use groupby and count on overnight, daytime and whole day segments\n",
    "(Work on Each metric one-by-one through a loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list variables to store manual and auto values\n",
    "# the value at index 0 is OVERNIGHT HGC (CGM > 170)\n",
    "#              index 1 is OVERNIGHT HGC_C (CGM > 250)\n",
    "#              index 2 is OVERNIGHT HGC_R1 (CGM between 70 and 180 inclusive)\n",
    "#              index 3 is OVERNIGHT HGC_R2 (CGM between 70 and 150 inclusive)\n",
    "#              index 4 is OVERNIGHT HGC_L1 (CGM < 70)\n",
    "#              index 5 is OVERNIGHT HGC_L2 (CGM < 54)\n",
    "# indices 6 to 11 are same ranges but for DAYTIME\n",
    "# indices 12 to 17 are same ranges but for WHOLE DAY\n",
    "man_hgc_vals = []\n",
    "aut_hgc_vals = []\n",
    "\n",
    "# inserting OVERNIGHT values\n",
    "for hgc_type in HGC_Ranges:\n",
    "    # MANUAL\n",
    "    ovrNight_Man_Perc = cgm_OvrNight_Man.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    ovrNight_Man_Avg = np.mean(ovrNight_Man_Perc.dropna())\n",
    "    #print(\"MANUAL OVERNIGHT \"+hgc_type+\" = \"+str(ovrNight_Man_Avg))\n",
    "    # add to the list\n",
    "    man_hgc_vals.append(ovrNight_Man_Avg)\n",
    "    \n",
    "    # AUTO\n",
    "    ovrNight_Aut_Perc = cgm_OvrNight_Aut.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    ovrNight_Aut_Avg = np.mean(ovrNight_Aut_Perc.dropna())\n",
    "    #print(\"AUTO OVERNIGHT \"+hgc_type+\" = \"+str(ovrNight_Aut_Avg))\n",
    "    # add to the list\n",
    "    aut_hgc_vals.append(ovrNight_Aut_Avg)\n",
    "    \n",
    "# inserting DAYTIME values\n",
    "for hgc_type in HGC_Ranges:\n",
    "    # MANUAL\n",
    "    dayTime_Man_Perc = cgm_DayTime_Man.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    dayTime_Man_Avg = np.mean(dayTime_Man_Perc.dropna())\n",
    "    #print(\"MANUAL DAYTIME \"+hgc_type+\" = \"+str(dayTime_Man_Avg))\n",
    "    # add to the list\n",
    "    man_hgc_vals.append(dayTime_Man_Avg)\n",
    "    \n",
    "    # AUTO\n",
    "    dayTime_Aut_Perc = cgm_DayTime_Aut.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    dayTime_Aut_Avg = np.mean(dayTime_Aut_Perc.dropna())\n",
    "    #print(\"AUTO DAYTIME \"+hgc_type+\" = \"+str(dayTime_Aut_Avg))\n",
    "    # add to the list\n",
    "    aut_hgc_vals.append(dayTime_Aut_Avg)\n",
    "    \n",
    "# inserting WHOLE DAY values\n",
    "for hgc_type in HGC_Ranges:\n",
    "    # MANUAL\n",
    "    wholeDay_Man_Perc = cgm_WholeDay_Man.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    wholeDay_Man_Avg = np.mean(wholeDay_Man_Perc.dropna())\n",
    "    #print(\"MANUAL WHOLE DAY \"+hgc_type+\" = \"+str(wholeDay_Man_Avg))\n",
    "    # add to the list\n",
    "    man_hgc_vals.append(wholeDay_Man_Avg)\n",
    "    \n",
    "    # AUTO\n",
    "    wholeDay_Aut_Perc = cgm_WholeDay_Aut.groupby(pd.Grouper(key='Date_Time', freq='1D'))[hgc_type].apply(lambda x: ((sum(x)/288)*100) if len(x)>0 else np.nan )\n",
    "    # average over all valid days\n",
    "    wholeDay_Aut_Avg = np.mean(wholeDay_Aut_Perc.dropna())\n",
    "    #print(\"AUTO WHOLE DAY \"+hgc_type+\" = \"+str(wholeDay_Aut_Avg))\n",
    "    # add to the list\n",
    "    aut_hgc_vals.append(wholeDay_Aut_Avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"MANUAL MODE VALUES: \")\n",
    "#print(man_hgc_vals)\n",
    "#print(\"AUTO MODE VALUES: \")\n",
    "#print(aut_hgc_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 8: convert results into 2x18 matrix and create Results.csv file for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2x18 matrix from the two lists\n",
    "results_matrix = np.row_stack((man_hgc_vals, aut_hgc_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CSV file of the results\n",
    "np.savetxt('Results.csv', results_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.6474359 ,  0.77457265, 18.48290598, 13.9957265 ,  0.77457265,\n",
       "         0.        , 24.70619658,  8.76068376, 39.1025641 , 30.42200855,\n",
       "         3.47222222,  1.5758547 , 29.35363248,  9.53525641, 57.58547009,\n",
       "        44.41773504,  4.24679487,  1.5758547 ],\n",
       "       [ 2.77777778,  0.42540471, 20.63097866, 17.93598234,  0.62086093,\n",
       "         0.15636497, 20.78993056,  5.05071272, 47.5717288 , 35.54915936,\n",
       "         3.57501827,  1.08506944, 23.54943348,  5.47331871, 68.06697734,\n",
       "        53.36714181,  4.19179459,  1.2404057 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
